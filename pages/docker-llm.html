<!DOCTYPE html>
<html lang="ko" data-theme="dark-kernel">
<head>
<script>
(function(){var m=document.cookie.match(/claude_theme=([^;]+)/);if(m)document.documentElement.setAttribute('data-theme',m[1]);})();
</script>
<meta charset="UTF-8">
<meta property="og:type" content="article">
<meta property="og:site_name" content="AI Vibe Coding ê°€ì´ë“œ /with MINZKN">
<meta property="og:title" content="Dockerë¡œ LLM í™˜ê²½ êµ¬ì¶•">
<meta property="og:description" content="Dockerë¡œ LLM í™˜ê²½ êµ¬ì¶•: ì»¨í…Œì´ë„ˆ ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ë˜ê³  ì´ì‹ ê°€ëŠ¥í•œ LLM ê°œë°œ í™˜ê²½ì„ êµ¬ì¶•í•˜ëŠ” ì™„ë²½í•œ ê°€ì´ë“œ">
<meta property="og:url" content="https://minzkn.com/claude/pages/docker-llm.html">
<meta property="og:image" content="https://minzkn.com/claude/images/og-image.png">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Dockerë¡œ LLM í™˜ê²½ êµ¬ì¶•: ì»¨í…Œì´ë„ˆ ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ë˜ê³  ì´ì‹ ê°€ëŠ¥í•œ LLM ê°œë°œ í™˜ê²½ì„ êµ¬ì¶•í•˜ëŠ” ì™„ë²½í•œ ê°€ì´ë“œ">
<meta name="keywords" content="Claude, AI, LLM, Dockerë¡œ LLM í™˜ê²½ êµ¬ì¶•, Docker ê¸°ë³¸ ì„¤ì •, Dockerë¡œ Ollama ì‹¤í–‰, ê°œë°œ í™˜ê²½ ì»¨í…Œì´ë„ˆí™”, ë³¼ë¥¨ ê´€ë¦¬">
<meta name="author" content="MINZKN">
<title>Dockerë¡œ LLM í™˜ê²½ êµ¬ì¶• - AI Vibe Coding ê°€ì´ë“œ /with MINZKN</title>
<link rel="icon" type="image/svg+xml" href="../images/favicon.svg">
<link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/joungkyun/font-d2coding/d2coding.css">
<link rel="stylesheet" href="../css/themes.css">
<link rel="stylesheet" href="../css/style.css">
<link rel="stylesheet" href="../css/responsive.css">
</head>
<body>
<div class="page-wrapper">

<header class="site-header"></header>
<nav class="side-nav" aria-label="ì‚¬ì´íŠ¸ ë‚´ë¹„ê²Œì´ì…˜"></nav>

<main class="main-content">
<nav class="breadcrumb"></nav>

<h1 id="top">Dockerë¡œ LLM í™˜ê²½ êµ¬ì¶•</h1>
<p class="lead">ì»¨í…Œì´ë„ˆ ê¸°ë°˜ìœ¼ë¡œ ì¼ê´€ë˜ê³  ì´ì‹ ê°€ëŠ¥í•œ LLM ê°œë°œ í™˜ê²½ì„ êµ¬ì¶•í•˜ëŠ” ì™„ë²½í•œ ê°€ì´ë“œ</p>

<div class="info-box warning">
  <strong>ì—…ë°ì´íŠ¸ ì•ˆë‚´:</strong> ëª¨ë¸/ìš”ê¸ˆ/ë²„ì „/ì •ì±… ë“± ì‹œì ì— ë¯¼ê°í•œ ì •ë³´ëŠ” ë³€ë™ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
  ìµœì‹  ë‚´ìš©ì€ ê³µì‹ ë¬¸ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”.
</div>

<div class="info-box tip">
  <div class="info-box-title">âš¡ Dockerë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ </div>
  <ul>
    <li><strong>ì¼ê´€ì„±</strong>: ëª¨ë“  íŒ€ì›ì´ ë™ì¼í•œ í™˜ê²½ì—ì„œ ì‘ì—…</li>
    <li><strong>ì´ì‹ì„±</strong>: ë¡œì»¬, í´ë¼ìš°ë“œ, CI/CD ì–´ë””ì„œë‚˜ ë™ì¼í•˜ê²Œ ì‹¤í–‰</li>
    <li><strong>ê²©ë¦¬</strong>: ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì¶©ëŒ ë°©ì§€</li>
    <li><strong>ì¬í˜„ì„±</strong>: Dockerfileë¡œ í™˜ê²½ì„ ì½”ë“œë¡œ ê´€ë¦¬</li>
    <li><strong>í™•ì¥ì„±</strong>: Docker Composeë¡œ ë©€í‹° ì„œë¹„ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜</li>
  </ul>
</div>

<section class="content-section">
  <h2 id="docker-basics">Docker ê¸°ë³¸ ì„¤ì •</h2>

  <h3 id="install-docker">Docker ì„¤ì¹˜</h3>

  <h4>macOS</h4>

<pre><code><span class="cmt"># Docker Desktop ì„¤ì¹˜</span>
brew install --cask docker

<span class="cmt"># ë˜ëŠ” https://www.docker.com/products/docker-desktop/ ì—ì„œ ë‹¤ìš´ë¡œë“œ</span>

<span class="cmt"># Docker Desktop ì‹¤í–‰ í›„ í™•ì¸</span>
docker --version
docker compose version</code></pre>

  <h4>Ubuntu/Debian</h4>

<pre><code><span class="cmt"># 1. ì´ì „ ë²„ì „ ì œê±°</span>
sudo apt remove docker docker-engine docker.io containerd runc

<span class="cmt"># 2. ì €ì¥ì†Œ ì„¤ì •</span>
sudo apt update
sudo apt install ca-certificates curl gnupg
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | \
  sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
sudo chmod a+r /etc/apt/keyrings/docker.gpg

echo \
  <span class="str">"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] \
  https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo $VERSION_CODENAME) stable"</span> | \
  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null

<span class="cmt"># 3. Docker ì„¤ì¹˜</span>
sudo apt update
sudo apt install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

<span class="cmt"># 4. ì‚¬ìš©ìë¥¼ docker ê·¸ë£¹ì— ì¶”ê°€ (sudo ì—†ì´ ì‚¬ìš©)</span>
sudo usermod -aG docker $USER
newgrp docker

<span class="cmt"># 5. í™•ì¸</span>
docker run hello-world</code></pre>

  <h4>Windows</h4>

<pre><code><span class="cmt"># Docker Desktop ë‹¤ìš´ë¡œë“œ ë° ì„¤ì¹˜</span>
<span class="cmt"># https://www.docker.com/products/docker-desktop/</span>

<span class="cmt"># WSL 2 ë°±ì—”ë“œ ì‚¬ìš© (ê¶Œì¥)</span>
<span class="cmt"># Settings â†’ General â†’ Use WSL 2 based engine</span>

<span class="cmt"># PowerShellì—ì„œ í™•ì¸</span>
docker --version
docker compose version</code></pre>

  <h3 id="docker-config">Docker ì„¤ì • ìµœì í™”</h3>

  <h4>macOS Docker Desktop ë¦¬ì†ŒìŠ¤ ì„¤ì •</h4>

<pre><code><span class="cmt"># Docker Desktop â†’ Settings â†’ Resources</span>

<span class="cmt"># ê¶Œì¥ ì„¤ì • (LLM ì›Œí¬ë¡œë“œìš©)</span>
CPUs: 4-8 (ì‹œìŠ¤í…œ ì½”ì–´ì˜ 50-75%)
Memory: 8-16 GB (LLM ëª¨ë¸ í¬ê¸°ì— ë”°ë¼)
Swap: 2 GB
Disk image size: 100 GB+</code></pre>

  <h4>Linux ë°ëª¬ ì„¤ì • (/etc/docker/daemon.json)</h4>

<pre><code>{
  <span class="str">"log-driver"</span>: <span class="str">"json-file"</span>,
  <span class="str">"log-opts"</span>: {
    <span class="str">"max-size"</span>: <span class="str">"10m"</span>,
    <span class="str">"max-file"</span>: <span class="str">"3"</span>
  },
  <span class="str">"storage-driver"</span>: <span class="str">"overlay2"</span>,
  <span class="str">"default-runtime"</span>: <span class="str">"runc"</span>
}

<span class="cmt"># ì ìš©</span>
sudo systemctl restart docker</code></pre>
</section>

<section class="content-section">
  <h2 id="ollama-docker">Dockerë¡œ Ollama ì‹¤í–‰</h2>

  <h3 id="ollama-basic">ê¸°ë³¸ ì‹¤í–‰</h3>

<pre><code><span class="cmt"># 1. Ollama ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì‹¤í–‰ (CPU ì „ìš©)</span>
docker run -d \
  --name ollama \
  -p 11434:11434 \
  -v ollama-data:/root/.ollama \
  ollama/ollama

<span class="cmt"># 2. ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸</span>
docker ps

<span class="cmt"># 3. ë¡œê·¸ í™•ì¸</span>
docker logs ollama

<span class="cmt"># 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ</span>
docker exec -it ollama ollama pull llama3.2:3b

<span class="cmt"># 5. ëŒ€í™”í˜• ì‹¤í–‰</span>
docker exec -it ollama ollama run llama3.2:3b

<span class="cmt"># 6. API í…ŒìŠ¤íŠ¸</span>
curl http://localhost:11434/api/generate -d <span class="str">'{
  "model": "llama3.2:3b",
  "prompt": "Why is the sky blue?",
  "stream": false
}'</span></code></pre>

  <h3 id="ollama-compose">Docker Composeë¡œ ê´€ë¦¬</h3>

  <h4>docker-compose.yml</h4>

<pre><code><span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="kw">ollama</span>:
    <span class="kw">image</span>: ollama/ollama:latest
    <span class="kw">container_name</span>: ollama
    <span class="kw">ports</span>:
      - <span class="str">"11434:11434"</span>
    <span class="kw">volumes</span>:
      - ollama-data:/root/.ollama
    <span class="kw">restart</span>: unless-stopped
    <span class="kw">environment</span>:
      - OLLAMA_HOST=0.0.0.0:11434
    <span class="kw">healthcheck</span>:
      <span class="kw">test</span>: [<span class="str">"CMD"</span>, <span class="str">"curl"</span>, <span class="str">"-f"</span>, <span class="str">"http://localhost:11434/api/tags"</span>]
      <span class="kw">interval</span>: 30s
      <span class="kw">timeout</span>: 10s
      <span class="kw">retries</span>: 3

<span class="kw">volumes</span>:
  <span class="kw">ollama-data</span>:
    <span class="kw">driver</span>: local</code></pre>

  <h4>ì‚¬ìš©ë²•</h4>

<pre><code><span class="cmt"># ì‹œì‘</span>
docker compose up -d

<span class="cmt"># ë¡œê·¸ í™•ì¸</span>
docker compose logs -f ollama

<span class="cmt"># ì¤‘ì§€</span>
docker compose down

<span class="cmt"># ë°ì´í„° í¬í•¨ ì™„ì „ ì‚­ì œ</span>
docker compose down -v

<span class="cmt"># ëª¨ë¸ ë‹¤ìš´ë¡œë“œ</span>
docker compose exec ollama ollama pull llama3.2:3b
docker compose exec ollama ollama pull codellama:7b
docker compose exec ollama ollama pull mistral:7b

<span class="cmt"># ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸</span>
docker compose exec ollama ollama list</code></pre>

  <h3 id="ollama-gpu">GPU ê°€ì† (NVIDIA)</h3>

  <div class="info-box info">
    <div class="info-box-title">ğŸ’¡ GPU ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­</div>
    <ul>
      <li>NVIDIA GPU í•„ìš” (CUDA 11.8+)</li>
      <li>Linux ë˜ëŠ” WSL 2 (Windows)</li>
      <li>NVIDIA Docker Runtime ì„¤ì¹˜ í•„ìš”</li>
      <li>macOSëŠ” Apple Silicon (Metal)ì„ ìë™ìœ¼ë¡œ ì‚¬ìš©</li>
    </ul>
  </div>

  <h4>1. NVIDIA Docker Runtime ì„¤ì¹˜ (Linux)</h4>

<pre><code><span class="cmt"># NVIDIA Container Toolkit ì„¤ì¹˜</span>
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | \
  sudo apt-key add -
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt update
sudo apt install -y nvidia-container-toolkit

<span class="cmt"># Docker ë°ëª¬ ì„¤ì •</span>
sudo nvidia-ctk runtime configure --runtime=docker
sudo systemctl restart docker

<span class="cmt"># í…ŒìŠ¤íŠ¸</span>
docker run --rm --gpus all nvidia/cuda:12.3.0-base-ubuntu22.04 nvidia-smi</code></pre>

  <h4>2. GPU ì§€ì› docker-compose.yml</h4>

<pre><code><span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="kw">ollama</span>:
    <span class="kw">image</span>: ollama/ollama:latest
    <span class="kw">container_name</span>: ollama-gpu
    <span class="kw">ports</span>:
      - <span class="str">"11434:11434"</span>
    <span class="kw">volumes</span>:
      - ollama-data:/root/.ollama
    <span class="kw">restart</span>: unless-stopped
    <span class="kw">deploy</span>:
      <span class="kw">resources</span>:
        <span class="kw">reservations</span>:
          <span class="kw">devices</span>:
            - <span class="kw">driver</span>: nvidia
              <span class="kw">count</span>: all  <span class="cmt"># ë˜ëŠ” 1 (GPU 1ê°œë§Œ)</span>
              <span class="kw">capabilities</span>: [gpu]
    <span class="kw">environment</span>:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_GPU_LAYERS=999  <span class="cmt"># ëª¨ë“  ë ˆì´ì–´ë¥¼ GPUì—</span>

<span class="kw">volumes</span>:
  <span class="kw">ollama-data</span>:</code></pre>

  <h4>3. GPU ì‚¬ìš© í™•ì¸</h4>

<pre><code><span class="cmt"># ì»¨í…Œì´ë„ˆ ë‚´ë¶€ì—ì„œ nvidia-smi ì‹¤í–‰</span>
docker compose exec ollama nvidia-smi

<span class="cmt"># Ollama ë¡œê·¸ì—ì„œ GPU ì‚¬ìš© í™•ì¸</span>
docker compose logs ollama | grep -i gpu
<span class="cmt"># ì¶œë ¥ ì˜ˆì‹œ: "GPU detected: NVIDIA GeForce RTX 4090"</span>

<span class="cmt"># ëª¨ë¸ ì‹¤í–‰ ì‹œ GPU ì‚¬ìš©ë¥  ëª¨ë‹ˆí„°ë§</span>
watch -n 1 nvidia-smi</code></pre>
</section>

<section class="content-section">
  <h2 id="dev-container">ê°œë°œ í™˜ê²½ ì»¨í…Œì´ë„ˆí™”</h2>

  <h3 id="python-llm">Python LLM ê°œë°œ í™˜ê²½</h3>

  <h4>Dockerfile</h4>

<pre><code><span class="cmt"># Dockerfile</span>
<span class="kw">FROM</span> python:3.12-slim

<span class="cmt"># ì‘ì—… ë””ë ‰í† ë¦¬ ì„¤ì •</span>
<span class="kw">WORKDIR</span> /app

<span class="cmt"># ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜</span>
<span class="kw">RUN</span> apt-get update && apt-get install -y \
    curl \
    git \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

<span class="cmt"># Python ì˜ì¡´ì„± ì„¤ì¹˜</span>
<span class="kw">COPY</span> requirements.txt .
<span class="kw">RUN</span> pip install --no-cache-dir -r requirements.txt

<span class="cmt"># ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬</span>
<span class="kw">COPY</span> . .

<span class="cmt"># ë¹„root ì‚¬ìš©ì ìƒì„±</span>
<span class="kw">RUN</span> useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app
<span class="kw">USER</span> appuser

<span class="cmt"># í¬íŠ¸ ë…¸ì¶œ</span>
<span class="kw">EXPOSE</span> 8000

<span class="cmt"># ì‹œì‘ ëª…ë ¹ì–´</span>
<span class="kw">CMD</span> [<span class="str">"python"</span>, <span class="str">"app.py"</span>]</code></pre>

  <h4>requirements.txt</h4>

<pre><code><span class="cmt"># LLM í´ë¼ì´ì–¸íŠ¸</span>
anthropic==0.18.1
openai==1.12.0
google-generativeai==0.3.2

<span class="cmt"># ë¡œì»¬ LLM</span>
ollama==0.1.6

<span class="cmt"># ì›¹ í”„ë ˆì„ì›Œí¬</span>
fastapi==0.109.2
uvicorn[standard]==0.27.1

<span class="cmt"># ìœ í‹¸ë¦¬í‹°</span>
python-dotenv==1.0.1
httpx==0.26.0
pydantic==2.6.1</code></pre>

  <h4>docker-compose.yml (ê°œë°œ í™˜ê²½)</h4>

<pre><code><span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="kw">app</span>:
    <span class="kw">build</span>: .
    <span class="kw">container_name</span>: llm-dev
    <span class="kw">ports</span>:
      - <span class="str">"8000:8000"</span>
    <span class="kw">volumes</span>:
      - .:/app                    <span class="cmt"># ì½”ë“œ hot reload</span>
      - /app/__pycache__          <span class="cmt"># ìºì‹œ ì œì™¸</span>
      - /app/.venv                <span class="cmt"># venv ì œì™¸</span>
    <span class="kw">environment</span>:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OLLAMA_HOST=http://ollama:11434
      - PYTHONUNBUFFERED=1
    <span class="kw">depends_on</span>:
      - ollama
    <span class="kw">command</span>: uvicorn app:app --host 0.0.0.0 --port 8000 --reload

  <span class="kw">ollama</span>:
    <span class="kw">image</span>: ollama/ollama:latest
    <span class="kw">container_name</span>: ollama
    <span class="kw">ports</span>:
      - <span class="str">"11434:11434"</span>
    <span class="kw">volumes</span>:
      - ollama-data:/root/.ollama

<span class="kw">volumes</span>:
  <span class="kw">ollama-data</span>:</code></pre>

  <h4>app.py (ì˜ˆì œ)</h4>

<pre><code><span class="kw">from</span> fastapi <span class="kw">import</span> FastAPI
<span class="kw">from</span> pydantic <span class="kw">import</span> BaseModel
<span class="kw">import</span> anthropic
<span class="kw">import</span> os

app = FastAPI()

<span class="kw">class</span> <span class="type">ChatRequest</span>(BaseModel):
    message: str
    model: str = <span class="str">"claude-<tier>"</span>

<span class="pp">@app.post</span>(<span class="str">"/chat"</span>)
<span class="kw">async def</span> <span class="fn">chat</span>(request: ChatRequest):
    client = anthropic.Anthropic(api_key=os.getenv(<span class="str">"ANTHROPIC_API_KEY"</span>))

    message = client.messages.create(
        model=request.model,
        max_tokens=1024,
        messages=[{<span class="str">"role"</span>: <span class="str">"user"</span>, <span class="str">"content"</span>: request.message}]
    )

    <span class="kw">return</span> {<span class="str">"response"</span>: message.content[0].text}

<span class="pp">@app.get</span>(<span class="str">"/health"</span>)
<span class="kw">async def</span> <span class="fn">health</span>():
    <span class="kw">return</span> {<span class="str">"status"</span>: <span class="str">"healthy"</span>}</code></pre>

  <h4>ì‚¬ìš©ë²•</h4>

<pre><code><span class="cmt"># .env íŒŒì¼ ìƒì„±</span>
cat &gt; .env &lt;&lt; <span class="str">EOF</span>
<span class="str">ANTHROPIC_API_KEY=sk-ant-api03-...</span>
<span class="str">OPENAI_API_KEY=sk-proj-...</span>
<span class="str">EOF</span>

<span class="cmt"># ë¹Œë“œ ë° ì‹œì‘</span>
docker compose up --build

<span class="cmt"># API í…ŒìŠ¤íŠ¸</span>
curl -X POST http://localhost:8000/chat \
  -H <span class="str">"Content-Type: application/json"</span> \
  -d <span class="str">'{"message": "Hello, Claude!"}'</span>

<span class="cmt"># ë¡œê·¸ í™•ì¸</span>
docker compose logs -f app</code></pre>

  <h3 id="nodejs-llm">Node.js LLM ê°œë°œ í™˜ê²½</h3>

  <h4>Dockerfile</h4>

<pre><code><span class="cmt"># Dockerfile</span>
<span class="kw">FROM</span> node:20-slim

<span class="kw">WORKDIR</span> /app

<span class="cmt"># ì˜ì¡´ì„± ì„¤ì¹˜</span>
<span class="kw">COPY</span> package*.json ./
<span class="kw">RUN</span> npm ci --only=production

<span class="cmt"># ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ</span>
<span class="kw">COPY</span> . .

<span class="cmt"># TypeScript ë¹Œë“œ (í•„ìš” ì‹œ)</span>
<span class="cmt"># RUN npm run build</span>

<span class="kw">EXPOSE</span> 3000

<span class="kw">CMD</span> [<span class="str">"node"</span>, <span class="str">"server.js"</span>]</code></pre>

  <h4>docker-compose.yml</h4>

<pre><code><span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="kw">app</span>:
    <span class="kw">build</span>: .
    <span class="kw">ports</span>:
      - <span class="str">"3000:3000"</span>
    <span class="kw">volumes</span>:
      - .:/app
      - /app/node_modules
    <span class="kw">environment</span>:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OLLAMA_HOST=http://ollama:11434
    <span class="kw">depends_on</span>:
      - ollama
    <span class="kw">command</span>: npm run dev

  <span class="kw">ollama</span>:
    <span class="kw">image</span>: ollama/ollama:latest
    <span class="kw">ports</span>:
      - <span class="str">"11434:11434"</span>
    <span class="kw">volumes</span>:
      - ollama-data:/root/.ollama

<span class="kw">volumes</span>:
  <span class="kw">ollama-data</span>:</code></pre>
</section>

<section class="content-section">
  <h2 id="volumes">ë³¼ë¥¨ ê´€ë¦¬</h2>

  <h3 id="volume-types">ë³¼ë¥¨ ìœ í˜•</h3>

  <table>
    <thead>
      <tr>
        <th>ìœ í˜•</th>
        <th>ì‚¬ìš© ì˜ˆ</th>
        <th>ì„±ëŠ¥</th>
        <th>ì´ì‹ì„±</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Named Volume</strong></td>
        <td>ëª¨ë¸, ë°ì´í„°ë² ì´ìŠ¤</td>
        <td>â­â­â­</td>
        <td>ë†’ìŒ</td>
      </tr>
      <tr>
        <td><strong>Bind Mount</strong></td>
        <td>ì†ŒìŠ¤ ì½”ë“œ, ì„¤ì •</td>
        <td>â­â­â­</td>
        <td>ì¤‘ê°„</td>
      </tr>
      <tr>
        <td><strong>tmpfs</strong></td>
        <td>ì„ì‹œ ìºì‹œ</td>
        <td>â­â­â­â­â­</td>
        <td>ë‚®ìŒ</td>
      </tr>
    </tbody>
  </table>

  <h3 id="volume-examples">ë³¼ë¥¨ ì‚¬ìš© ì˜ˆì œ</h3>

<pre><code><span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="kw">ollama</span>:
    <span class="kw">image</span>: ollama/ollama:latest
    <span class="kw">volumes</span>:
      <span class="cmt"># Named volume (ëª¨ë¸ ì˜êµ¬ ì €ì¥)</span>
      - ollama-models:/root/.ollama/models

      <span class="cmt"># Bind mount (ì»¤ìŠ¤í…€ Modelfile)</span>
      - ./modelfiles:/modelfiles:ro

      <span class="cmt"># tmpfs (ì„ì‹œ ìºì‹œ)</span>
      - type: tmpfs
        target: /tmp
        tmpfs:
          size: 1G

<span class="kw">volumes</span>:
  <span class="kw">ollama-models</span>:
    <span class="kw">driver</span>: local
    <span class="kw">driver_opts</span>:
      <span class="kw">type</span>: none
      <span class="kw">o</span>: bind
      <span class="kw">device</span>: /mnt/ssd/ollama  <span class="cmt"># SSD ê²½ë¡œ</span></code></pre>

  <h3 id="volume-management">ë³¼ë¥¨ ê´€ë¦¬ ëª…ë ¹ì–´</h3>

<pre><code><span class="cmt"># ë³¼ë¥¨ ëª©ë¡</span>
docker volume ls

<span class="cmt"># ë³¼ë¥¨ ìƒì„¸ ì •ë³´</span>
docker volume inspect ollama-data

<span class="cmt"># ë³¼ë¥¨ ë°±ì—…</span>
docker run --rm \
  -v ollama-data:/source \
  -v $(pwd):/backup \
  alpine tar czf /backup/ollama-backup.tar.gz -C /source .

<span class="cmt"># ë³¼ë¥¨ ë³µì›</span>
docker run --rm \
  -v ollama-data:/target \
  -v $(pwd):/backup \
  alpine tar xzf /backup/ollama-backup.tar.gz -C /target

<span class="cmt"># ë³¼ë¥¨ ì‚­ì œ (ì£¼ì˜!)</span>
docker volume rm ollama-data

<span class="cmt"># ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë³¼ë¥¨ ì •ë¦¬</span>
docker volume prune</code></pre>

  <h3 id="volume-backup">ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸</h3>

<pre><code><span class="pp">#!/bin/bash</span>
<span class="cmt"># backup-ollama.sh</span>

<span class="kw">BACKUP_DIR</span>=<span class="str">"$HOME/backups/ollama"</span>
<span class="kw">DATE</span>=$(date +%Y%m%d_%H%M%S)
<span class="kw">BACKUP_FILE</span>=<span class="str">"$BACKUP_DIR/ollama-$DATE.tar.gz"</span>

mkdir -p <span class="str">"$BACKUP_DIR"</span>

docker run --rm \
  -v ollama-data:/source \
  -v <span class="str">"$BACKUP_DIR"</span>:/backup \
  alpine tar czf /backup/<span class="str">"ollama-$DATE.tar.gz"</span> -C /source .

echo <span class="str">"âœ… Backup completed: $BACKUP_FILE"</span>

<span class="cmt"># 30ì¼ ì´ìƒ ëœ ë°±ì—… ì‚­ì œ</span>
find <span class="str">"$BACKUP_DIR"</span> -name <span class="str">"ollama-*.tar.gz"</span> -mtime +30 -delete</code></pre>

<pre><code><span class="cmt"># cronì— ë“±ë¡ (ë§¤ì¼ ìƒˆë²½ 2ì‹œ)</span>
crontab -e
<span class="cmt"># ì¶”ê°€:</span>
0 2 * * * /path/to/backup-ollama.sh</code></pre>
</section>

<section class="content-section">
  <h2 id="networking">ë„¤íŠ¸ì›Œí‚¹</h2>

  <h3 id="network-types">ë„¤íŠ¸ì›Œí¬ ìœ í˜•</h3>

  <table>
    <thead>
      <tr>
        <th>ìœ í˜•</th>
        <th>ìš©ë„</th>
        <th>ì»¨í…Œì´ë„ˆ ê°„ í†µì‹ </th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>bridge</strong></td>
        <td>ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬</td>
        <td>ê°™ì€ ë„¤íŠ¸ì›Œí¬ ë‚´ ê°€ëŠ¥</td>
      </tr>
      <tr>
        <td><strong>host</strong></td>
        <td>í˜¸ìŠ¤íŠ¸ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš©</td>
        <td>í˜¸ìŠ¤íŠ¸ì™€ ë™ì¼</td>
      </tr>
      <tr>
        <td><strong>none</strong></td>
        <td>ë„¤íŠ¸ì›Œí¬ ì—†ìŒ</td>
        <td>ë¶ˆê°€</td>
      </tr>
      <tr>
        <td><strong>custom</strong></td>
        <td>ì‚¬ìš©ì ì •ì˜ ë„¤íŠ¸ì›Œí¬</td>
        <td>DNS ìë™ í•´ì„</td>
      </tr>
    </tbody>
  </table>

  <h3 id="network-custom">ì»¤ìŠ¤í…€ ë„¤íŠ¸ì›Œí¬ ì˜ˆì œ</h3>

<pre><code><span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="kw">frontend</span>:
    <span class="kw">build</span>: ./frontend
    <span class="kw">networks</span>:
      - public
      - internal
    <span class="kw">ports</span>:
      - <span class="str">"3000:3000"</span>

  <span class="kw">backend</span>:
    <span class="kw">build</span>: ./backend
    <span class="kw">networks</span>:
      - internal
    <span class="kw">environment</span>:
      - OLLAMA_HOST=http://ollama:11434

  <span class="kw">ollama</span>:
    <span class="kw">image</span>: ollama/ollama:latest
    <span class="kw">networks</span>:
      - internal
    <span class="kw">volumes</span>:
      - ollama-data:/root/.ollama

<span class="kw">networks</span>:
  <span class="kw">public</span>:
    <span class="kw">driver</span>: bridge
  <span class="kw">internal</span>:
    <span class="kw">driver</span>: bridge
    <span class="kw">internal</span>: <span class="kw">true</span>  <span class="cmt"># ì™¸ë¶€ ì ‘ê·¼ ì°¨ë‹¨</span>

<span class="kw">volumes</span>:
  <span class="kw">ollama-data</span>:</code></pre>

  <h3 id="network-commands">ë„¤íŠ¸ì›Œí¬ ê´€ë¦¬ ëª…ë ¹ì–´</h3>

<pre><code><span class="cmt"># ë„¤íŠ¸ì›Œí¬ ëª©ë¡</span>
docker network ls

<span class="cmt"># ë„¤íŠ¸ì›Œí¬ ìƒì„±</span>
docker network create llm-network

<span class="cmt"># ì»¨í…Œì´ë„ˆë¥¼ ë„¤íŠ¸ì›Œí¬ì— ì—°ê²°</span>
docker network connect llm-network ollama

<span class="cmt"># ë„¤íŠ¸ì›Œí¬ ìƒì„¸ ì •ë³´</span>
docker network inspect llm-network

<span class="cmt"># ë„¤íŠ¸ì›Œí¬ì—ì„œ ë¶„ë¦¬</span>
docker network disconnect llm-network ollama

<span class="cmt"># ë„¤íŠ¸ì›Œí¬ ì‚­ì œ</span>
docker network rm llm-network</code></pre>
</section>

<section class="content-section">
  <h2 id="multi-service">ë©€í‹° ì„œë¹„ìŠ¤ êµ¬ì„±</h2>

  <h3 id="full-stack">í’€ìŠ¤íƒ LLM ì• í”Œë¦¬ì¼€ì´ì…˜</h3>

  <h4>docker-compose.yml (í”„ë¡œë•ì…˜)</h4>

<pre><code><span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="cmt"># Nginx ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ</span>
  <span class="kw">nginx</span>:
    <span class="kw">image</span>: nginx:alpine
    <span class="kw">ports</span>:
      - <span class="str">"80:80"</span>
      - <span class="str">"443:443"</span>
    <span class="kw">volumes</span>:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    <span class="kw">depends_on</span>:
      - frontend
      - backend
    <span class="kw">networks</span>:
      - public

  <span class="cmt"># React í”„ë¡ íŠ¸ì—”ë“œ</span>
  <span class="kw">frontend</span>:
    <span class="kw">build</span>: ./frontend
    <span class="kw">expose</span>:
      - <span class="str">"3000"</span>
    <span class="kw">networks</span>:
      - public

  <span class="cmt"># FastAPI ë°±ì—”ë“œ</span>
  <span class="kw">backend</span>:
    <span class="kw">build</span>: ./backend
    <span class="kw">expose</span>:
      - <span class="str">"8000"</span>
    <span class="kw">environment</span>:
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - OLLAMA_HOST=http://ollama:11434
      - DATABASE_URL=postgresql://user:pass@postgres:5432/llmdb
      - REDIS_URL=redis://redis:6379
    <span class="kw">depends_on</span>:
      - postgres
      - redis
      - ollama
    <span class="kw">networks</span>:
      - public
      - backend

  <span class="cmt"># Ollama LLM ì„œë²„</span>
  <span class="kw">ollama</span>:
    <span class="kw">image</span>: ollama/ollama:latest
    <span class="kw">expose</span>:
      - <span class="str">"11434"</span>
    <span class="kw">volumes</span>:
      - ollama-data:/root/.ollama
    <span class="kw">deploy</span>:
      <span class="kw">resources</span>:
        <span class="kw">reservations</span>:
          <span class="kw">devices</span>:
            - <span class="kw">driver</span>: nvidia
              <span class="kw">count</span>: 1
              <span class="kw">capabilities</span>: [gpu]
    <span class="kw">networks</span>:
      - backend

  <span class="cmt"># PostgreSQL ë°ì´í„°ë² ì´ìŠ¤</span>
  <span class="kw">postgres</span>:
    <span class="kw">image</span>: postgres:16-alpine
    <span class="kw">environment</span>:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
      - POSTGRES_DB=llmdb
    <span class="kw">volumes</span>:
      - postgres-data:/var/lib/postgresql/data
    <span class="kw">networks</span>:
      - backend

  <span class="cmt"># Redis ìºì‹œ</span>
  <span class="kw">redis</span>:
    <span class="kw">image</span>: redis:7-alpine
    <span class="kw">command</span>: redis-server --appendonly yes
    <span class="kw">volumes</span>:
      - redis-data:/data
    <span class="kw">networks</span>:
      - backend

<span class="kw">networks</span>:
  <span class="kw">public</span>:
    <span class="kw">driver</span>: bridge
  <span class="kw">backend</span>:
    <span class="kw">driver</span>: bridge
    <span class="kw">internal</span>: <span class="kw">true</span>

<span class="kw">volumes</span>:
  <span class="kw">ollama-data</span>:
  <span class="kw">postgres-data</span>:
  <span class="kw">redis-data</span>:</code></pre>

  <h4>nginx.conf</h4>

<pre><code><span class="kw">upstream</span> frontend {
    server frontend:3000;
}

<span class="kw">upstream</span> backend {
    server backend:8000;
}

<span class="kw">server</span> {
    <span class="kw">listen</span> 80;
    <span class="kw">server_name</span> example.com;

    <span class="cmt"># í”„ë¡ íŠ¸ì—”ë“œ</span>
    <span class="kw">location</span> / {
        <span class="kw">proxy_pass</span> http://frontend;
        <span class="kw">proxy_set_header</span> Host $host;
        <span class="kw">proxy_set_header</span> X-Real-IP $remote_addr;
    }

    <span class="cmt"># ë°±ì—”ë“œ API</span>
    <span class="kw">location</span> /api/ {
        <span class="kw">proxy_pass</span> http://backend;
        <span class="kw">proxy_set_header</span> Host $host;
        <span class="kw">proxy_set_header</span> X-Real-IP $remote_addr;

        <span class="cmt"># ìŠ¤íŠ¸ë¦¬ë° ì§€ì›</span>
        <span class="kw">proxy_buffering</span> off;
        <span class="kw">proxy_read_timeout</span> 300s;
    }
}</code></pre>
</section>

<section class="content-section">
  <h2 id="production">í”„ë¡œë•ì…˜ ë°°í¬</h2>

  <h3 id="prod-dockerfile">í”„ë¡œë•ì…˜ Dockerfile ìµœì í™”</h3>

  <h4>ë©€í‹° ìŠ¤í…Œì´ì§€ ë¹Œë“œ</h4>

<pre><code><span class="cmt"># ========== Stage 1: Build ==========</span>
<span class="kw">FROM</span> node:20-alpine <span class="kw">AS</span> builder

<span class="kw">WORKDIR</span> /app

<span class="cmt"># ì˜ì¡´ì„± ì„¤ì¹˜</span>
<span class="kw">COPY</span> package*.json ./
<span class="kw">RUN</span> npm ci

<span class="cmt"># ë¹Œë“œ</span>
<span class="kw">COPY</span> . .
<span class="kw">RUN</span> npm run build

<span class="cmt"># ========== Stage 2: Production ==========</span>
<span class="kw">FROM</span> node:20-alpine

<span class="kw">WORKDIR</span> /app

<span class="cmt"># í”„ë¡œë•ì…˜ ì˜ì¡´ì„±ë§Œ ì„¤ì¹˜</span>
<span class="kw">COPY</span> package*.json ./
<span class="kw">RUN</span> npm ci --only=production

<span class="cmt"># ë¹Œë“œ ê²°ê³¼ë¬¼ë§Œ ë³µì‚¬</span>
<span class="kw">COPY</span> --from=builder /app/dist ./dist

<span class="cmt"># ë³´ì•ˆ: ë¹„root ì‚¬ìš©ì</span>
<span class="kw">RUN</span> addgroup -g 1001 -S nodejs && \
    adduser -S nodejs -u 1001
<span class="kw">USER</span> nodejs

<span class="cmt"># í—¬ìŠ¤ì²´í¬</span>
<span class="kw">HEALTHCHECK</span> --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD node healthcheck.js

<span class="kw">EXPOSE</span> 3000

<span class="kw">CMD</span> [<span class="str">"node"</span>, <span class="str">"dist/server.js"</span>]</code></pre>

  <h3 id="prod-compose">í”„ë¡œë•ì…˜ Compose ì„¤ì •</h3>

<pre><code><span class="cmt"># docker-compose.prod.yml</span>
<span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="kw">app</span>:
    <span class="kw">build</span>:
      <span class="kw">context</span>: .
      <span class="kw">dockerfile</span>: Dockerfile
      <span class="kw">target</span>: production
    <span class="kw">restart</span>: always
    <span class="kw">deploy</span>:
      <span class="kw">replicas</span>: 3
      <span class="kw">update_config</span>:
        <span class="kw">parallelism</span>: 1
        <span class="kw">delay</span>: 10s
      <span class="kw">restart_policy</span>:
        <span class="kw">condition</span>: on-failure
        <span class="kw">max_attempts</span>: 3
    <span class="kw">environment</span>:
      - NODE_ENV=production
      - LOG_LEVEL=info
    <span class="kw">logging</span>:
      <span class="kw">driver</span>: <span class="str">"json-file"</span>
      <span class="kw">options</span>:
        <span class="kw">max-size</span>: <span class="str">"10m"</span>
        <span class="kw">max-file</span>: <span class="str">"3"</span></code></pre>

  <h3 id="prod-security">ë³´ì•ˆ ê°•í™”</h3>

  <h4>1. ì‹œí¬ë¦¿ ê´€ë¦¬ (Docker Swarm)</h4>

<pre><code><span class="cmt"># ì‹œí¬ë¦¿ ìƒì„±</span>
echo <span class="str">"sk-ant-api03-..."</span> | docker secret create anthropic_key -

<span class="cmt"># docker-compose.yml</span>
<span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="kw">app</span>:
    <span class="kw">image</span>: myapp:latest
    <span class="kw">secrets</span>:
      - anthropic_key
    <span class="kw">environment</span>:
      - ANTHROPIC_API_KEY_FILE=/run/secrets/anthropic_key

<span class="kw">secrets</span>:
  <span class="kw">anthropic_key</span>:
    <span class="kw">external</span>: <span class="kw">true</span></code></pre>

  <h4>2. ì½ê¸° ì „ìš© íŒŒì¼ ì‹œìŠ¤í…œ</h4>

<pre><code><span class="kw">services</span>:
  <span class="kw">app</span>:
    <span class="kw">read_only</span>: <span class="kw">true</span>
    <span class="kw">tmpfs</span>:
      - /tmp
      - /var/run</code></pre>

  <h4>3. ë¦¬ì†ŒìŠ¤ ì œí•œ</h4>

<pre><code><span class="kw">services</span>:
  <span class="kw">app</span>:
    <span class="kw">deploy</span>:
      <span class="kw">resources</span>:
        <span class="kw">limits</span>:
          <span class="kw">cpus</span>: <span class="str">'2.0'</span>
          <span class="kw">memory</span>: 4G
        <span class="kw">reservations</span>:
          <span class="kw">cpus</span>: <span class="str">'1.0'</span>
          <span class="kw">memory</span>: 2G</code></pre>

  <h3 id="prod-monitoring">ëª¨ë‹ˆí„°ë§</h3>

<pre><code><span class="cmt"># docker-compose.monitoring.yml</span>
<span class="kw">version</span>: <span class="str">'3.8'</span>

<span class="kw">services</span>:
  <span class="kw">prometheus</span>:
    <span class="kw">image</span>: prom/prometheus:latest
    <span class="kw">volumes</span>:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    <span class="kw">ports</span>:
      - <span class="str">"9090:9090"</span>

  <span class="kw">grafana</span>:
    <span class="kw">image</span>: grafana/grafana:latest
    <span class="kw">ports</span>:
      - <span class="str">"3001:3000"</span>
    <span class="kw">environment</span>:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    <span class="kw">volumes</span>:
      - grafana-data:/var/lib/grafana

  <span class="kw">cadvisor</span>:
    <span class="kw">image</span>: gcr.io/cadvisor/cadvisor:latest
    <span class="kw">volumes</span>:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    <span class="kw">ports</span>:
      - <span class="str">"8080:8080"</span>

<span class="kw">volumes</span>:
  <span class="kw">prometheus-data</span>:
  <span class="kw">grafana-data</span>:</code></pre>
</section>

<section class="content-section">
  <h2 id="troubleshooting">ë¬¸ì œ í•´ê²°</h2>

  <h3 id="trouble-common">ì¼ë°˜ì ì¸ ë¬¸ì œ</h3>

  <h4>1. ì»¨í…Œì´ë„ˆê°€ ì‹œì‘ë˜ì§€ ì•ŠìŒ</h4>

<pre><code><span class="cmt"># ë¡œê·¸ í™•ì¸</span>
docker compose logs app

<span class="cmt"># ì»¨í…Œì´ë„ˆ ìƒíƒœ í™•ì¸</span>
docker ps -a

<span class="cmt"># ì´ë¯¸ì§€ ì¬ë¹Œë“œ</span>
docker compose build --no-cache app
docker compose up app</code></pre>

  <h4>2. ë³¼ë¥¨ ê¶Œí•œ ë¬¸ì œ</h4>

<pre><code><span class="cmt"># ë³¼ë¥¨ ì†Œìœ ê¶Œ ë³€ê²½</span>
docker run --rm \
  -v ollama-data:/data \
  alpine chown -R 1000:1000 /data

<span class="cmt"># Dockerfileì—ì„œ USER ì§€ì •</span>
<span class="kw">RUN</span> chown -R appuser:appuser /app
<span class="kw">USER</span> appuser</code></pre>

  <h4>3. GPUê°€ ì¸ì‹ë˜ì§€ ì•ŠìŒ</h4>

<pre><code><span class="cmt"># NVIDIA Docker Runtime í™•ì¸</span>
docker run --rm --gpus all nvidia/cuda:12.3.0-base-ubuntu22.04 nvidia-smi

<span class="cmt"># ë°ëª¬ ì„¤ì • í™•ì¸</span>
cat /etc/docker/daemon.json

<span class="cmt"># Docker ì¬ì‹œì‘</span>
sudo systemctl restart docker</code></pre>

  <h4>4. ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ</h4>

<pre><code><span class="cmt"># ì»¨í…Œì´ë„ˆ ê°„ í•‘ í…ŒìŠ¤íŠ¸</span>
docker compose exec app ping ollama

<span class="cmt"># DNS í™•ì¸</span>
docker compose exec app nslookup ollama

<span class="cmt"># ë„¤íŠ¸ì›Œí¬ ì¬ìƒì„±</span>
docker compose down
docker network prune
docker compose up -d</code></pre>

  <h3 id="trouble-performance">ì„±ëŠ¥ ìµœì í™”</h3>

<pre><code><span class="cmt"># 1. ë¹Œë“œ ìºì‹œ í™œìš©</span>
<span class="cmt"># Dockerfileì—ì„œ ìì£¼ ë³€ê²½ë˜ì§€ ì•ŠëŠ” ê²ƒì„ ë¨¼ì € COPY</span>
<span class="kw">COPY</span> package*.json ./
<span class="kw">RUN</span> npm install
<span class="kw">COPY</span> . .

<span class="cmt"># 2. .dockerignore ì‚¬ìš©</span>
<span class="cmt"># .dockerignore</span>
node_modules
.git
.env
*.log

<span class="cmt"># 3. ë©€í‹° ìŠ¤í…Œì´ì§€ ë¹Œë“œë¡œ ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ</span>
<span class="cmt"># ìµœì¢… ì´ë¯¸ì§€ì— í•„ìš”í•œ íŒŒì¼ë§Œ í¬í•¨</span></code></pre>
</section>

<section class="content-section">
  <h2 id="best-practices">ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤</h2>

  <ul>
    <li><strong>ì‘ì€ ë² ì´ìŠ¤ ì´ë¯¸ì§€</strong>: alpine ë˜ëŠ” slim ì‚¬ìš©</li>
    <li><strong>ë©€í‹° ìŠ¤í…Œì´ì§€ ë¹Œë“œ</strong>: ë¹Œë“œ ì˜ì¡´ì„± ì œì™¸</li>
    <li><strong>.dockerignore</strong>: ë¶ˆí•„ìš”í•œ íŒŒì¼ ì œì™¸</li>
    <li><strong>ë ˆì´ì–´ ìµœì í™”</strong>: RUN ëª…ë ¹ì–´ ê²°í•©</li>
    <li><strong>ìºì‹œ í™œìš©</strong>: ìì£¼ ë³€ê²½ë˜ëŠ” ê²ƒì„ ë§ˆì§€ë§‰ì— COPY</li>
    <li><strong>ë¹„root ì‚¬ìš©ì</strong>: ë³´ì•ˆ ê°•í™”</li>
    <li><strong>í—¬ìŠ¤ì²´í¬</strong>: ì»¨í…Œì´ë„ˆ ìƒíƒœ ëª¨ë‹ˆí„°ë§</li>
    <li><strong>ë¡œê¹…</strong>: ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì •</li>
    <li><strong>ë¦¬ì†ŒìŠ¤ ì œí•œ</strong>: CPU/ë©”ëª¨ë¦¬ ì œí•œ</li>
    <li><strong>ì‹œí¬ë¦¿ ê´€ë¦¬</strong>: í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” Secrets ì‚¬ìš©</li>
  </ul>

  <div class="info-box tip">
    <div class="info-box-title">ğŸš€ ë‹¤ìŒ ë‹¨ê³„</div>
    <ul>
      <li><a href="ci-cd-llm.html">CI/CD & LLM</a> - Docker ì´ë¯¸ì§€ ìë™ ë¹Œë“œ ë° ë°°í¬</li>
      <li><a href="monitoring-costs.html">ë¹„ìš© ëª¨ë‹ˆí„°ë§</a> - ì»¨í…Œì´ë„ˆ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶”ì </li>
      <li><a href="dev-environment.html">LLM ê°œë°œ í™˜ê²½</a> - ë¡œì»¬ ê°œë°œ í™˜ê²½ ì„¤ì •</li>
    </ul>
  </div>
</section>

<section class="content-section">
  <h2 id="summary">í•µì‹¬ ì •ë¦¬</h2>
  <ul>
    <li>Dockerë¡œ LLM í™˜ê²½ êµ¬ì¶•ì˜ í•µì‹¬ ê°œë…ê³¼ íë¦„ì„ ì •ë¦¬í•©ë‹ˆë‹¤.</li>
    <li>Docker ê¸°ë³¸ ì„¤ì •ë¥¼ ë‹¨ê³„ë³„ë¡œ ì´í•´í•©ë‹ˆë‹¤.</li>
    <li>ì‹¤ì „ ì ìš© ì‹œ ê¸°ì¤€ê³¼ ì£¼ì˜ì ì„ í™•ì¸í•©ë‹ˆë‹¤.</li>
  </ul>
</section>

<section class="content-section">
  <h2 id="practice-tips">ì‹¤ë¬´ íŒ</h2>
  <ul>
    <li>ì…ë ¥/ì¶œë ¥ ì˜ˆì‹œë¥¼ ê³ ì •í•´ ì¬í˜„ì„±ì„ í™•ë³´í•˜ì„¸ìš”.</li>
    <li>Dockerë¡œ LLM í™˜ê²½ êµ¬ì¶• ë²”ìœ„ë¥¼ ì‘ê²Œ ì¡ê³  ë‹¨ê³„ì ìœ¼ë¡œ í™•ì¥í•˜ì„¸ìš”.</li>
    <li>Docker ê¸°ë³¸ ì„¤ì • ì¡°ê±´ì„ ë¬¸ì„œí™”í•´ ëŒ€ì‘ ì‹œê°„ì„ ì¤„ì´ì„¸ìš”.</li>
  </ul>
</section>
<nav class="page-nav"></nav>
</main>

<aside class="inline-toc">
  <div class="toc-title">ëª©ì°¨</div>
  <div class="toc-nav"></div>
</aside>
<footer class="site-footer"></footer>

</div>
<script src="../js/main.js"></script>
</body>
</html>
