#!/usr/bin/env python3
"""
ë§í¬ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
- ë‚´ë¶€ í˜ì´ì§€ ë§í¬ í™•ì¸
- ì•µì»¤ ë§í¬ í™•ì¸
- CSS/JS ë¦¬ì†ŒìŠ¤ í™•ì¸
- ì™¸ë¶€ ë§í¬ í˜•ì‹ í™•ì¸
"""

import os
import re
from pathlib import Path
from urllib.parse import urlparse
from collections import defaultdict

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent
PAGES_DIR = PROJECT_ROOT / "pages"
CSS_DIR = PROJECT_ROOT / "css"
JS_DIR = PROJECT_ROOT / "js"

def extract_links(html_content, file_path):
    """HTMLì—ì„œ ëª¨ë“  ë§í¬ ì¶”ì¶œ"""
    links = {
        'internal': [],  # ë‚´ë¶€ í˜ì´ì§€ ë§í¬
        'anchor': [],    # ì•µì»¤ ë§í¬
        'css': [],       # CSS íŒŒì¼
        'js': [],        # JS íŒŒì¼
        'external': []   # ì™¸ë¶€ ë§í¬
    }

    # href ì†ì„± ì¶”ì¶œ
    href_pattern = r'href=["\']([^"\']+)["\']'
    for match in re.finditer(href_pattern, html_content):
        href = match.group(1)

        if href.startswith('http://') or href.startswith('https://'):
            links['external'].append(href)
        elif href.startswith('#'):
            links['anchor'].append(href[1:])  # # ì œê±°
        elif href.endswith('.html'):
            links['internal'].append(href)
        elif href.endswith('.css'):
            links['css'].append(href)

    # src ì†ì„±ì—ì„œ JS ì¶”ì¶œ
    src_pattern = r'src=["\']([^"\']+\.js)["\']'
    for match in re.finditer(src_pattern, html_content):
        links['js'].append(match.group(1))

    return links

def extract_ids(html_content):
    """HTMLì—ì„œ ëª¨ë“  id ì†ì„± ì¶”ì¶œ"""
    id_pattern = r'id=["\']([^"\']+)["\']'
    return [match.group(1) for match in re.finditer(id_pattern, html_content)]

def resolve_path(current_file, link):
    """ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""
    current_dir = current_file.parent
    resolved = (current_dir / link).resolve()
    return resolved

def check_links():
    """ëª¨ë“  HTML íŒŒì¼ì˜ ë§í¬ ê²€ì‚¬"""
    issues = defaultdict(list)
    stats = {
        'total_files': 0,
        'total_links': 0,
        'broken_internal': 0,
        'broken_anchor': 0,
        'broken_resource': 0
    }

    # ëª¨ë“  HTML íŒŒì¼ ê²€ì‚¬
    html_files = list(PAGES_DIR.glob('*.html'))
    html_files.append(PROJECT_ROOT / 'index.html')

    stats['total_files'] = len(html_files)

    # ê° íŒŒì¼ì˜ id ëª©ë¡ ë¯¸ë¦¬ ìˆ˜ì§‘ (ì•µì»¤ ê²€ì¦ìš©)
    file_ids = {}
    for html_file in html_files:
        with open(html_file, 'r', encoding='utf-8') as f:
            content = f.read()
            file_ids[html_file.name] = extract_ids(content)

    # ë§í¬ ê²€ì¦
    for html_file in html_files:
        with open(html_file, 'r', encoding='utf-8') as f:
            content = f.read()

        links = extract_links(content, html_file)
        stats['total_links'] += sum(len(v) for v in links.values())

        # 1. ë‚´ë¶€ í˜ì´ì§€ ë§í¬ ê²€ì¦
        for link in links['internal']:
            target_path = resolve_path(html_file, link)
            if not target_path.exists():
                issues[html_file.name].append(f"âŒ ê¹¨ì§„ ë‚´ë¶€ ë§í¬: {link} â†’ {target_path}")
                stats['broken_internal'] += 1

        # 2. ì•µì»¤ ë§í¬ ê²€ì¦
        for anchor in links['anchor']:
            # í˜„ì¬ íŒŒì¼ì˜ id í™•ì¸
            current_ids = file_ids.get(html_file.name, [])
            if anchor not in current_ids:
                issues[html_file.name].append(f"âš ï¸  ì•µì»¤ ID ì—†ìŒ: #{anchor}")
                stats['broken_anchor'] += 1

        # 3. CSS íŒŒì¼ ê²€ì¦
        for css_link in links['css']:
            css_path = resolve_path(html_file, css_link)
            if not css_path.exists():
                issues[html_file.name].append(f"âŒ CSS íŒŒì¼ ì—†ìŒ: {css_link}")
                stats['broken_resource'] += 1

        # 4. JS íŒŒì¼ ê²€ì¦
        for js_link in links['js']:
            js_path = resolve_path(html_file, js_link)
            if not js_path.exists():
                issues[html_file.name].append(f"âŒ JS íŒŒì¼ ì—†ìŒ: {js_link}")
                stats['broken_resource'] += 1

    return issues, stats

def main():
    print("ğŸ” ë§í¬ ê²€ì¦ ì‹œì‘...\n")

    issues, stats = check_links()

    # ê²°ê³¼ ì¶œë ¥
    print("=" * 70)
    print("ğŸ“Š ê²€ì‚¬ í†µê³„")
    print("=" * 70)
    print(f"ê²€ì‚¬í•œ íŒŒì¼ ìˆ˜: {stats['total_files']}")
    print(f"ì´ ë§í¬ ìˆ˜: {stats['total_links']}")
    print(f"ê¹¨ì§„ ë‚´ë¶€ ë§í¬: {stats['broken_internal']}")
    print(f"ëˆ„ë½ëœ ì•µì»¤: {stats['broken_anchor']}")
    print(f"ëˆ„ë½ëœ ë¦¬ì†ŒìŠ¤: {stats['broken_resource']}")
    print()

    if not any(issues.values()):
        print("âœ… ëª¨ë“  ë§í¬ê°€ ì •ìƒì…ë‹ˆë‹¤!")
        return 0

    # ë¬¸ì œê°€ ìˆëŠ” íŒŒì¼ ì¶œë ¥
    print("=" * 70)
    print("âš ï¸  ë°œê²¬ëœ ë¬¸ì œ")
    print("=" * 70)

    for filename, file_issues in sorted(issues.items()):
        print(f"\nğŸ“„ {filename}")
        for issue in file_issues:
            print(f"  {issue}")

    print("\n" + "=" * 70)
    total_issues = sum(len(v) for v in issues.values())
    print(f"ì´ {total_issues}ê°œì˜ ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")

    return 1

if __name__ == '__main__':
    exit(main())
