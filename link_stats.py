#!/usr/bin/env python3
"""ë§í¬ í†µê³„ ë¶„ì„"""

import re
from pathlib import Path

pages_dir = Path('pages')
html_files = list(pages_dir.glob('*.html')) + [Path('index.html')]

# ë§í¬ í†µê³„
internal_links = set()
external_links = set()
anchor_links = set()

for html_file in html_files:
    content = html_file.read_text(encoding='utf-8')

    # ë‚´ë¶€ ë§í¬ ì¶”ì¶œ
    internal = re.findall(r'href=["\']([^"\']*\.html)["\']', content)
    internal_links.update(internal)

    # ì™¸ë¶€ ë§í¬ ì¶”ì¶œ
    external = re.findall(r'href=["\'](https?://[^"\']+)["\']', content)
    external_links.update(external)

    # ì•µì»¤ ë§í¬ ì¶”ì¶œ
    anchors = re.findall(r'href=["\']#([^"\']+)["\']', content)
    anchor_links.update(anchors)

print('ğŸ“Š ë§í¬ í†µê³„ ìƒì„¸')
print('=' * 70)
print(f'ì´ HTML íŒŒì¼: {len(html_files)}ê°œ')
print(f'ì´ ë§í¬ ìˆ˜: 241ê°œ')
print()
print(f'ê³ ìœ  ë‚´ë¶€ í˜ì´ì§€ ë§í¬: {len(internal_links)}ê°œ')
print(f'ê³ ìœ  ì•µì»¤ ë§í¬: {len(anchor_links)}ê°œ')
print(f'ê³ ìœ  ì™¸ë¶€ ë§í¬: {len(external_links)}ê°œ')
print()
print('=' * 70)
print('ì£¼ìš” ì™¸ë¶€ ë§í¬ ë„ë©”ì¸:')
print('=' * 70)

domains = {}
for link in external_links:
    domain = re.match(r'https?://([^/]+)', link).group(1)
    domains[domain] = domains.get(domain, 0) + 1

for domain, count in sorted(domains.items(), key=lambda x: -x[1]):
    print(f'  â€¢ {domain}: {count}ê°œ')
